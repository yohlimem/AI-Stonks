{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mplfinance as mpf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW THINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"AAPL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open t - 1</th>\n",
       "      <th>Close t - 1</th>\n",
       "      <th>High t - 1</th>\n",
       "      <th>Low t - 1</th>\n",
       "      <th>Open t - 2</th>\n",
       "      <th>...</th>\n",
       "      <th>Low t - 8</th>\n",
       "      <th>Open t - 9</th>\n",
       "      <th>Close t - 9</th>\n",
       "      <th>High t - 9</th>\n",
       "      <th>Low t - 9</th>\n",
       "      <th>Open t - 10</th>\n",
       "      <th>Close t - 10</th>\n",
       "      <th>High t - 10</th>\n",
       "      <th>Low t - 10</th>\n",
       "      <th>movement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-12 09:30:00-04:00</th>\n",
       "      <td>229.000000</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>228.679993</td>\n",
       "      <td>230.880005</td>\n",
       "      <td>14080146</td>\n",
       "      <td>227.720001</td>\n",
       "      <td>227.550003</td>\n",
       "      <td>228.699997</td>\n",
       "      <td>227.550003</td>\n",
       "      <td>227.259995</td>\n",
       "      <td>...</td>\n",
       "      <td>231.705002</td>\n",
       "      <td>232.100006</td>\n",
       "      <td>231.759995</td>\n",
       "      <td>232.190002</td>\n",
       "      <td>231.630005</td>\n",
       "      <td>231.570007</td>\n",
       "      <td>232.100006</td>\n",
       "      <td>232.149994</td>\n",
       "      <td>231.520004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-12 10:30:00-04:00</th>\n",
       "      <td>230.880005</td>\n",
       "      <td>232.397995</td>\n",
       "      <td>230.619995</td>\n",
       "      <td>231.899902</td>\n",
       "      <td>7527748</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>230.880005</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>228.679993</td>\n",
       "      <td>227.720001</td>\n",
       "      <td>...</td>\n",
       "      <td>228.529999</td>\n",
       "      <td>231.759995</td>\n",
       "      <td>232.910004</td>\n",
       "      <td>233.080002</td>\n",
       "      <td>231.705002</td>\n",
       "      <td>232.100006</td>\n",
       "      <td>231.759995</td>\n",
       "      <td>232.190002</td>\n",
       "      <td>231.630005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-12 11:30:00-04:00</th>\n",
       "      <td>231.899994</td>\n",
       "      <td>231.990005</td>\n",
       "      <td>230.509995</td>\n",
       "      <td>230.710007</td>\n",
       "      <td>5014273</td>\n",
       "      <td>230.880005</td>\n",
       "      <td>231.899902</td>\n",
       "      <td>232.397995</td>\n",
       "      <td>230.619995</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>226.270004</td>\n",
       "      <td>231.311707</td>\n",
       "      <td>228.899994</td>\n",
       "      <td>232.389999</td>\n",
       "      <td>228.529999</td>\n",
       "      <td>231.759995</td>\n",
       "      <td>232.910004</td>\n",
       "      <td>233.080002</td>\n",
       "      <td>231.705002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-12 12:30:00-04:00</th>\n",
       "      <td>230.710007</td>\n",
       "      <td>231.910004</td>\n",
       "      <td>230.570007</td>\n",
       "      <td>231.902496</td>\n",
       "      <td>4220317</td>\n",
       "      <td>231.899994</td>\n",
       "      <td>230.710007</td>\n",
       "      <td>231.990005</td>\n",
       "      <td>230.509995</td>\n",
       "      <td>230.880005</td>\n",
       "      <td>...</td>\n",
       "      <td>225.770004</td>\n",
       "      <td>228.869995</td>\n",
       "      <td>226.619995</td>\n",
       "      <td>229.639999</td>\n",
       "      <td>226.270004</td>\n",
       "      <td>231.311707</td>\n",
       "      <td>228.899994</td>\n",
       "      <td>232.389999</td>\n",
       "      <td>228.529999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-12 13:30:00-04:00</th>\n",
       "      <td>231.899994</td>\n",
       "      <td>232.639999</td>\n",
       "      <td>231.839996</td>\n",
       "      <td>232.270004</td>\n",
       "      <td>4525973</td>\n",
       "      <td>230.710007</td>\n",
       "      <td>231.902496</td>\n",
       "      <td>231.910004</td>\n",
       "      <td>230.570007</td>\n",
       "      <td>231.899994</td>\n",
       "      <td>...</td>\n",
       "      <td>227.270004</td>\n",
       "      <td>226.619995</td>\n",
       "      <td>227.765793</td>\n",
       "      <td>227.839996</td>\n",
       "      <td>225.770004</td>\n",
       "      <td>228.869995</td>\n",
       "      <td>226.619995</td>\n",
       "      <td>229.639999</td>\n",
       "      <td>226.270004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-12 14:30:00-04:00</th>\n",
       "      <td>232.264999</td>\n",
       "      <td>232.360001</td>\n",
       "      <td>231.559998</td>\n",
       "      <td>231.859894</td>\n",
       "      <td>3484723</td>\n",
       "      <td>231.899994</td>\n",
       "      <td>232.270004</td>\n",
       "      <td>232.639999</td>\n",
       "      <td>231.839996</td>\n",
       "      <td>230.710007</td>\n",
       "      <td>...</td>\n",
       "      <td>226.589996</td>\n",
       "      <td>227.759995</td>\n",
       "      <td>227.979996</td>\n",
       "      <td>228.720001</td>\n",
       "      <td>227.270004</td>\n",
       "      <td>226.619995</td>\n",
       "      <td>227.765793</td>\n",
       "      <td>227.839996</td>\n",
       "      <td>225.770004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-12 15:30:00-04:00</th>\n",
       "      <td>231.860001</td>\n",
       "      <td>231.869995</td>\n",
       "      <td>229.910004</td>\n",
       "      <td>230.570007</td>\n",
       "      <td>5822133</td>\n",
       "      <td>232.264999</td>\n",
       "      <td>231.859894</td>\n",
       "      <td>232.360001</td>\n",
       "      <td>231.559998</td>\n",
       "      <td>231.899994</td>\n",
       "      <td>...</td>\n",
       "      <td>227.210007</td>\n",
       "      <td>227.970001</td>\n",
       "      <td>227.264999</td>\n",
       "      <td>227.975006</td>\n",
       "      <td>226.589996</td>\n",
       "      <td>227.759995</td>\n",
       "      <td>227.979996</td>\n",
       "      <td>228.720001</td>\n",
       "      <td>227.270004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Datetime                                                                    \n",
       "2024-07-12 09:30:00-04:00  229.000000  231.500000  228.679993  230.880005   \n",
       "2024-07-12 10:30:00-04:00  230.880005  232.397995  230.619995  231.899902   \n",
       "2024-07-12 11:30:00-04:00  231.899994  231.990005  230.509995  230.710007   \n",
       "2024-07-12 12:30:00-04:00  230.710007  231.910004  230.570007  231.902496   \n",
       "2024-07-12 13:30:00-04:00  231.899994  232.639999  231.839996  232.270004   \n",
       "2024-07-12 14:30:00-04:00  232.264999  232.360001  231.559998  231.859894   \n",
       "2024-07-12 15:30:00-04:00  231.860001  231.869995  229.910004  230.570007   \n",
       "\n",
       "                             Volume  Open t - 1  Close t - 1  High t - 1  \\\n",
       "Datetime                                                                   \n",
       "2024-07-12 09:30:00-04:00  14080146  227.720001   227.550003  228.699997   \n",
       "2024-07-12 10:30:00-04:00   7527748  229.000000   230.880005  231.500000   \n",
       "2024-07-12 11:30:00-04:00   5014273  230.880005   231.899902  232.397995   \n",
       "2024-07-12 12:30:00-04:00   4220317  231.899994   230.710007  231.990005   \n",
       "2024-07-12 13:30:00-04:00   4525973  230.710007   231.902496  231.910004   \n",
       "2024-07-12 14:30:00-04:00   3484723  231.899994   232.270004  232.639999   \n",
       "2024-07-12 15:30:00-04:00   5822133  232.264999   231.859894  232.360001   \n",
       "\n",
       "                            Low t - 1  Open t - 2  ...   Low t - 8  \\\n",
       "Datetime                                           ...               \n",
       "2024-07-12 09:30:00-04:00  227.550003  227.259995  ...  231.705002   \n",
       "2024-07-12 10:30:00-04:00  228.679993  227.720001  ...  228.529999   \n",
       "2024-07-12 11:30:00-04:00  230.619995  229.000000  ...  226.270004   \n",
       "2024-07-12 12:30:00-04:00  230.509995  230.880005  ...  225.770004   \n",
       "2024-07-12 13:30:00-04:00  230.570007  231.899994  ...  227.270004   \n",
       "2024-07-12 14:30:00-04:00  231.839996  230.710007  ...  226.589996   \n",
       "2024-07-12 15:30:00-04:00  231.559998  231.899994  ...  227.210007   \n",
       "\n",
       "                           Open t - 9  Close t - 9  High t - 9   Low t - 9  \\\n",
       "Datetime                                                                     \n",
       "2024-07-12 09:30:00-04:00  232.100006   231.759995  232.190002  231.630005   \n",
       "2024-07-12 10:30:00-04:00  231.759995   232.910004  233.080002  231.705002   \n",
       "2024-07-12 11:30:00-04:00  231.311707   228.899994  232.389999  228.529999   \n",
       "2024-07-12 12:30:00-04:00  228.869995   226.619995  229.639999  226.270004   \n",
       "2024-07-12 13:30:00-04:00  226.619995   227.765793  227.839996  225.770004   \n",
       "2024-07-12 14:30:00-04:00  227.759995   227.979996  228.720001  227.270004   \n",
       "2024-07-12 15:30:00-04:00  227.970001   227.264999  227.975006  226.589996   \n",
       "\n",
       "                           Open t - 10  Close t - 10  High t - 10  Low t - 10  \\\n",
       "Datetime                                                                        \n",
       "2024-07-12 09:30:00-04:00   231.570007    232.100006   232.149994  231.520004   \n",
       "2024-07-12 10:30:00-04:00   232.100006    231.759995   232.190002  231.630005   \n",
       "2024-07-12 11:30:00-04:00   231.759995    232.910004   233.080002  231.705002   \n",
       "2024-07-12 12:30:00-04:00   231.311707    228.899994   232.389999  228.529999   \n",
       "2024-07-12 13:30:00-04:00   228.869995    226.619995   229.639999  226.270004   \n",
       "2024-07-12 14:30:00-04:00   226.619995    227.765793   227.839996  225.770004   \n",
       "2024-07-12 15:30:00-04:00   227.759995    227.979996   228.720001  227.270004   \n",
       "\n",
       "                           movement  \n",
       "Datetime                             \n",
       "2024-07-12 09:30:00-04:00         1  \n",
       "2024-07-12 10:30:00-04:00         1  \n",
       "2024-07-12 11:30:00-04:00         0  \n",
       "2024-07-12 12:30:00-04:00         1  \n",
       "2024-07-12 13:30:00-04:00         1  \n",
       "2024-07-12 14:30:00-04:00         0  \n",
       "2024-07-12 15:30:00-04:00         0  \n",
       "\n",
       "[7 rows x 46 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_data(stock_name, period=\"5d\", interval=\"1m\",back_time=5):\n",
    "\n",
    "    recent_data = yf.download(stock_name, period=period, interval=interval)\n",
    "    recent_data = recent_data.drop(columns=[\"Adj Close\"])\n",
    "    recent_data.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "    for i in range(back_time):\n",
    "        recent_data[f\"Open t - {i+1}\"] = recent_data[\"Open\"].shift((i+1))\n",
    "        recent_data[f\"Close t - {i+1}\"] = recent_data[\"Close\"].shift((i+1))\n",
    "        recent_data[f\"High t - {i+1}\"] = recent_data[\"High\"].shift((i+1))\n",
    "        recent_data[f\"Low t - {i+1}\"] = recent_data[\"Low\"].shift((i+1))\n",
    "\n",
    "    recent_data.dropna(inplace=True)\n",
    "    first_timestamp = recent_data.index[0]\n",
    "\n",
    "    if first_timestamp.time() != pd.Timestamp(\"09:30:00\").time():\n",
    "        index = recent_data.index.get_loc(recent_data[\n",
    "            recent_data.index.time == pd.Timestamp(\"09:30:00\").time()\n",
    "        ].index[0])\n",
    "        print(index)\n",
    "        recent_data = recent_data.iloc[index:]\n",
    "    # print(recent_data.iloc[0])\n",
    "    recent_data[\"movement\"] = (recent_data[\"Close\"] > recent_data[\"Open\"]).astype(int)\n",
    "\n",
    "    return recent_data\n",
    "\n",
    "def split_data(recent_data, interval=\"1m\"):\n",
    "    segment = 390 if interval == \"1m\" else 7\n",
    "    if type(recent_data) == pd.DataFrame:\n",
    "        day_segments = [\n",
    "            recent_data.iloc[i : i + segment] for i in range(0, len(recent_data), segment)\n",
    "        ]\n",
    "    else:\n",
    "        day_segments = torch.from_numpy(np.array([\n",
    "            recent_data[i : i + segment] for i in range(0, len(recent_data), segment)\n",
    "        ]))\n",
    "    return day_segments\n",
    "\n",
    "recent_data = prepare_data(\n",
    "    stock_name, back_time=10, period=\"1mo\", interval=\"1h\"\n",
    ")\n",
    "\n",
    "day_segments = split_data(recent_data, interval=\"1h\")\n",
    "\n",
    "\n",
    "recent_data.head()\n",
    "day_segments = day_segments[0]\n",
    "day_segments[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147, 41])\n",
      "torch.Size([147, 1])\n",
      "torch.Size([21, 7, 41])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "\n",
    "X = recent_data.drop([\"Close\", \"Volume\", \"High\", \"Low\",\"movement\"], axis=1)\n",
    "y = recent_data[[\"movement\"]]\n",
    "\n",
    "X_tensor = torch.from_numpy(X.values)\n",
    "y_tensor = torch.from_numpy(y.values)\n",
    "print(X_tensor.shape)\n",
    "print(y_tensor.shape)\n",
    "# print(X)\n",
    "\n",
    "print(split_data(X_tensor, interval=\"1h\").shape)\n",
    "\n",
    "print(split_data(X_tensor, interval=\"1h\").shape)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_tensor,y_tensor,test_size=0.2)\n",
    "X_train = X_train.to(torch.float32).to(device)\n",
    "# X_time_step = [i for i in range(len(X_train))]\n",
    "X_test= X_test.to(torch.float32).to(device)\n",
    "y_train = y_train.to(torch.float32).to(device)\n",
    "y_test =y_test.to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=2):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "\n",
    "        self.ltsm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "    def forward(self, sequences):\n",
    "        lstm_out, (hn, cn) = self.ltsm(sequences)\n",
    "        return lstm_out\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    \n",
    "    LSTMPredictor(input_size=42, hidden_size=128, n_layers=10),\n",
    "    nn.Linear(128, 3),\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "# model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[218.0500, 218.2800, 217.7950,  ..., 222.6000, 223.0100, 222.0801],\n",
       "        [234.5500, 234.8100, 234.3995,  ..., 234.6900, 235.8800, 234.6200],\n",
       "        [209.4500, 208.5050, 209.0100,  ..., 212.6150, 213.0000, 209.5050],\n",
       "        ...,\n",
       "        [231.9000, 230.7100, 230.8800,  ..., 232.9100, 233.0800, 231.7050],\n",
       "        [225.0600, 224.6800, 224.3700,  ..., 223.9450, 225.0500, 223.5600],\n",
       "        [222.9800, 223.3500, 227.8700,  ..., 234.8100, 234.9800, 234.2850]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yahli\\anaconda3\\envs\\Stocks\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([120, 1])) that is different to the input size (torch.Size([120, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\yahli\\anaconda3\\envs\\Stocks\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([30, 1])) that is different to the input size (torch.Size([30, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss = 0.5180712342262268, test loss = 0.33002859354019165\n",
      "epoch: 100 loss = 0.24900199472904205, test loss = 0.25493112206459045\n",
      "epoch: 200 loss = 0.2421465367078781, test loss = 0.25643104314804077\n",
      "epoch: 300 loss = 0.23525935411453247, test loss = 0.25656113028526306\n",
      "epoch: 400 loss = 0.25251445174217224, test loss = 0.2520330250263214\n",
      "epoch: 500 loss = 0.23902182281017303, test loss = 0.24695584177970886\n",
      "epoch: 600 loss = 0.23703745007514954, test loss = 0.23847584426403046\n",
      "epoch: 700 loss = 0.2318083494901657, test loss = 0.23384281992912292\n",
      "epoch: 800 loss = 0.22248727083206177, test loss = 0.2339828610420227\n",
      "epoch: 900 loss = 0.21531745791435242, test loss = 0.273252010345459\n",
      "epoch: 1000 loss = 0.20839254558086395, test loss = 0.3173498511314392\n",
      "epoch: 1100 loss = 0.22593697905540466, test loss = 0.2466966211795807\n",
      "epoch: 1200 loss = 0.2190409004688263, test loss = 0.26273536682128906\n",
      "epoch: 1300 loss = 0.24034790694713593, test loss = 0.2403080016374588\n",
      "epoch: 1400 loss = 0.23326300084590912, test loss = 0.2226547747850418\n",
      "epoch: 1500 loss = 0.26843157410621643, test loss = 0.247096985578537\n",
      "epoch: 1600 loss = 0.2423500120639801, test loss = 0.25278240442276\n",
      "epoch: 1700 loss = 0.24109426140785217, test loss = 0.24895630776882172\n",
      "epoch: 1800 loss = 0.23760737478733063, test loss = 0.23487402498722076\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 15\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n",
      "File \u001b[1;32mc:\\Users\\yahli\\anaconda3\\envs\\Stocks\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yahli\\anaconda3\\envs\\Stocks\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\yahli\\anaconda3\\envs\\Stocks\\Lib\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\yahli\\anaconda3\\envs\\Stocks\\Lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yahli\\anaconda3\\envs\\Stocks\\Lib\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yahli\\anaconda3\\envs\\Stocks\\Lib\\site-packages\\torch\\optim\\adam.py:602\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    600\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 602\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[0;32m    605\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "for batch in range(day_segments.shape[0]):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            y_test_pred = model(X_test)\n",
    "            test_loss = loss_fn(y_test_pred, y_test)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"epoch: {epoch} loss = {loss}, test loss = {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_loop_data(stock_name, period=\"5d\", interval=\"1m\",back_time=5, answers =[]):\n",
    "\n",
    "    recent_data = yf.download(stock_name, period=period, interval=interval)\n",
    "\n",
    "    data_200 = yf.download(stock_name, period=period, interval=interval).tail(len(recent_data) + 201)\n",
    "    data_200 = data_200.drop(columns=[\"Adj Close\"])\n",
    "\n",
    "    data_200.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "    #recent_data = data_200.tail(len(recent_data))\n",
    "\n",
    "\n",
    "    recent_data = recent_data.dropna()\n",
    "    for i in range(back_time):\n",
    "        recent_data[f\"Open t - {i+1}\"] = recent_data[\"Open\"].shift((i+1))\n",
    "        recent_data[f\"Close t - {i+1}\"] = recent_data[\"Close\"].shift((i+1))\n",
    "        recent_data[f\"High t - {i+1}\"] = recent_data[\"High\"].shift((i+1))\n",
    "        recent_data[f\"Low t - {i+1}\"] = recent_data[\"Low\"].shift((i+1))\n",
    "    recent_data[\"movement\"] = (recent_data[\"Close\"] > recent_data[\"Open\"]).astype(int)\n",
    "\n",
    "    # recent_data = recent_data.tail(1)\n",
    "    # add_plot = mpf.make_addplot(recent_data[\"200_day\"], color=\"blue\", linestyle=\"--\")\n",
    "\n",
    "    return recent_data\n",
    "\n",
    "#recent_data = prepare_test_loop_data(stock_name,back_time=1,answers=[answer])\n",
    "#recent_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 46\u001b[0m\n\u001b[0;32m     40\u001b[0m answer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(answer[\u001b[38;5;241m0\u001b[39m],check_X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose t - 1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     41\u001b[0m answers\u001b[38;5;241m.\u001b[39mappend(answer)\n\u001b[0;32m     42\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     43\u001b[0m     {\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m: [answers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m\"\u001b[39m: [answers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]],\n\u001b[1;32m---> 46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m\"\u001b[39m: [answers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m]],\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m\"\u001b[39m: [answers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m3\u001b[39m]],\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     50\u001b[0m     },\n\u001b[0;32m     51\u001b[0m     index\u001b[38;5;241m=\u001b[39m[date_range[i]],\n\u001b[0;32m     52\u001b[0m )\n\u001b[0;32m     54\u001b[0m check_data \u001b[38;5;241m=\u001b[39m check_data\u001b[38;5;241m.\u001b[39m_append(df)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "answers = []\n",
    "forcast = 10\n",
    "check_data = prepare_test_loop_data(\n",
    "    interval=\"1m\", back_time=10, period=\"1d\", stock_name=stock_name\n",
    ")\n",
    "date_range = pd.date_range(\n",
    "    start=check_data.index[-1], periods=forcast, freq=\"1T\"\n",
    ")  # Generate a date range\n",
    "\n",
    "\n",
    "\n",
    "for i in range(forcast):\n",
    "    # for i in answers:\n",
    "\n",
    "    check_data_last = check_data.tail(1)\n",
    "    check_X = check_data_last.drop([\"Close\", \"Volume\", \"High\", \"Low\",\"movement\"], axis=1)\n",
    "    check_y = check_data_last[[\"movement\"]]\n",
    "\n",
    "    # print(check_data.tail(6).to_markdown())\n",
    "    # print(X.shape)\n",
    "\n",
    "    check_X_tensor = torch.from_numpy(check_X.values)\n",
    "    check_y_tensor = torch.from_numpy(check_y.values)\n",
    "\n",
    "    check_X_tensor = check_X_tensor.to(torch.float32).to(device)\n",
    "    check_y_tensor = check_y_tensor.to(torch.float32).to(device)\n",
    "\n",
    "    # print(check_data_last.to_markdown(), \"\\n\\n\\n\")\n",
    "\n",
    "    answer = model(check_X_tensor)\n",
    "    a = torch.softmax(answer, dim=1).argmax(dim=1)\n",
    "    print(a)\n",
    "\n",
    "    answer = answer.detach().cpu().numpy()\n",
    "\n",
    "    answer = np.append(answer[0],check_X[\"Close t - 1\"])\n",
    "    answers.append(answer)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Close\": [answers[-1][0]],\n",
    "            \"High\": [answers[-1][1]],\n",
    "            \"Low\": [answers[-1][2]],\n",
    "            \"Open\": [answers[-1][3]],\n",
    "            \"Adj Close\": [0],\n",
    "            \"Volume\": [0],\n",
    "        },\n",
    "        index=[date_range[i]],\n",
    "    )\n",
    "\n",
    "    check_data = check_data._append(df)\n",
    "    for i in range(10):\n",
    "        check_data[f\"Open t - {i+1}\"] = check_data[\"Open\"].shift((i + 1))\n",
    "        check_data[f\"Close t - {i+1}\"] = check_data[\"Close\"].shift((i + 1))\n",
    "        check_data[f\"High t - {i+1}\"] = check_data[\"High\"].shift((i + 1))\n",
    "        check_data[f\"Low t - {i+1}\"] = check_data[\"Low\"].shift((i + 1))\n",
    "    recent_data[\"movement\"] = (recent_data[\"Close\"] > recent_data[\"Open\"]).astype(int)\n",
    "\n",
    "    # check_data.dropna(inplace=True)\n",
    "# print(check_data.to_markdown())\n",
    "\n",
    "# print(check_data)\n",
    "# print(answers)\n",
    "\n",
    "# sns.catplot(answer[0][:],label=\"Predicted\")\n",
    "last_elements = [arr[0] for arr in answers]\n",
    "\n",
    "recent_data = prepare_data(stock_name, period=\"1d\", interval=\"1m\")\n",
    "# print(\"Converted index to datetime\")\n",
    "\n",
    "answers_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            recent_data,\n",
    "            columns=[\"Close\", \"High\", \"Low\", \"Open\",\"movement\"],\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            answers, columns=[\"movement\"], index=date_range\n",
    "        ),\n",
    "    ]\n",
    ").iloc[200:]\n",
    "\n",
    "# print(answers_df.tail(100))\n",
    "\n",
    "mpf.plot(\n",
    "    answers_df,\n",
    "    type=\"candle\",\n",
    "    style=\"charles\",\n",
    "    title=f\"{stock_name} Candlestick Chart\",\n",
    "    ylabel=\"Price\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 64\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 24\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Build model\n",
    "class stonks(nn.Module):\n",
    "    def __init__(self, input_features, output_features, hidden_units=8):\n",
    "\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "             nn.ReLU(), \n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features), \n",
    "            nn.Sigmoid(),\n",
    "     \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "# Create an instance of BlobModel and send it to the target device\n",
    "model = stonks(input_features=X_train.size()[1], \n",
    "                    output_features=1, \n",
    "                    hidden_units=8).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss and optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=0.1) # exercise: try changing the learning rate here and seeing what happens to the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1976e-05],\n",
      "        [6.7180e-05],\n",
      "        [2.2683e-05],\n",
      "        [2.2327e-05]], grad_fn=<SliceBackward0>)\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Make prediction logits with model\n",
    "y_logits = model(X_test.to(device))\n",
    "\n",
    "# Perform softmax calculation on logits across dimension 1 to get prediction probabilities\n",
    "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "print(y_logits[:5])\n",
    "print(y_pred_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 100 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 200 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 300 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 400 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 500 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 600 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 700 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 800 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 900 | Loss: 75.00000,| Test Loss: 2.40205\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "#torch.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 1000\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = model(X_train) # model outputs raw logits \n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
    "    # print(y_logits)\n",
    "    # 2. Calculate loss and accuracy\n",
    "  \n",
    "    loss = loss_fn(y_pred.to(torch.float32), y_train.squeeze()) \n",
    "  \n",
    "\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.requires_grad = True\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass\n",
    "      test_logits = model(X_test)\n",
    "      test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "      # 2. Calculate test loss and accuracy\n",
    "      test_loss = loss_fn(test_logits, y_test)\n",
    "\n",
    "\n",
    "    # Print out what's happening\n",
    "      if epoch % 100 == 0:\n",
    "          print(f\"Epoch: {epoch} | Loss: {loss:.5f},| Test Loss: {test_loss:.5f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
