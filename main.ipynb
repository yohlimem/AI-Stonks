{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mplfinance as mpf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW THINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"AAPL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 30)\n"
     ]
    }
   ],
   "source": [
    "def prepare_daily_data(stock_name, period=\"5d\", interval=\"1m\"):\n",
    "    recent_data = yf.download(stock_name, period=period, interval=interval)\n",
    "    recent_data = recent_data.drop(columns=[\"Adj Close\", \"Volume\"])\n",
    "\n",
    "    segment = 390 if interval == \"1m\" else 7\n",
    "\n",
    "    for i in range(1, segment):\n",
    "        recent_data[f\"Open t - {i}\"] = recent_data[\"Open\"].shift(i)\n",
    "        recent_data[f\"Close t - {i}\"] = recent_data[\"Close\"].shift(i)\n",
    "        recent_data[f\"High t - {i}\"] = recent_data[\"High\"].shift(i)\n",
    "        recent_data[f\"Low t - {i}\"] = recent_data[\"Low\"].shift(i)\n",
    "\n",
    "    recent_data.dropna(inplace=True)\n",
    "    first_timestamp = recent_data.index[0]\n",
    "\n",
    "    if first_timestamp.time() != pd.Timestamp(\"09:30:00\").time():\n",
    "        index = recent_data.index.get_loc(\n",
    "            recent_data[\n",
    "                recent_data.index.time == pd.Timestamp(\"09:30:00\").time()\n",
    "            ].index[0]\n",
    "        )\n",
    "        recent_data = recent_data.iloc[index:]\n",
    "\n",
    "    # Split data into daily segments\n",
    "    recent_data[\"day_index\"] = recent_data.index.date\n",
    "    recent_data[\"day_index\"], _ = pd.factorize(recent_data[\"day_index\"])\n",
    "    daily_data = [group for _, group in recent_data.groupby(\"day_index\")]\n",
    "\n",
    "    # Add movement column to each daily DataFrame\n",
    "    for day_data in daily_data:\n",
    "        day_data[\"movement\"] = (\n",
    "            day_data[\"Close\"].iloc[-1] > day_data[\"Open\"].iloc[0]\n",
    "        ).astype(int)\n",
    "\n",
    "    day_data[\"movement\"] = day_data[\"movement\"].shift(-1)\n",
    "\n",
    "    combined_data = pd.concat(daily_data)\n",
    "\n",
    "    last_hour_data = combined_data.groupby(\"day_index\").apply(lambda x: x.iloc[-1])\n",
    "    last_hour_data.dropna(inplace=True)\n",
    "\n",
    "    return last_hour_data\n",
    "\n",
    "daily_data = prepare_daily_data(stock_name, period=\"1y\", interval=\"1h\")\n",
    "\n",
    "print(daily_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 29])\n",
      "torch.Size([50, 29])\n",
      "tensor([[188.9600, 188.9900, 188.5100,  ..., 187.6500, 185.8300, 107.0000],\n",
      "        [171.8550, 172.5200, 171.7800,  ..., 173.6300, 170.8200,  34.0000],\n",
      "        [226.8100, 227.8400, 226.7601,  ..., 227.3500, 223.2500, 224.0000],\n",
      "        ...,\n",
      "        [171.5800, 171.6400, 170.4400,  ..., 170.0100, 167.6200,  31.0000],\n",
      "        [224.6800, 225.0400, 223.7800,  ..., 227.7800, 225.5800, 234.0000],\n",
      "        [218.6200, 218.6200, 217.1300,  ..., 219.1499, 216.0100, 238.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "\n",
    "X = daily_data.drop(columns=[\"movement\"])\n",
    "y = daily_data[\"movement\"]\n",
    "\n",
    "X_tensor = torch.from_numpy(X.values)\n",
    "# X_tensor.requires_grad=True\n",
    "y_tensor = torch.from_numpy(y.values)\n",
    "# y_tensor.requires_grad = True\n",
    "\n",
    "# print(X)\n",
    "\n",
    "# print(split_data(X_tensor, interval=\"1h\").shape)\n",
    "\n",
    "#print(split_data(X_tensor, interval=\"1h\").shape)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_tensor,y_tensor,test_size=0.2)\n",
    "X_train = X_train.to(torch.float32).to(device)\n",
    "# X_time_step = [i for i in range(len(X_train))]\n",
    "X_test= X_test.to(torch.float32).to(device)\n",
    "y_train = y_train.to(torch.float32).to(device)\n",
    "y_test =y_test.to(torch.float32).to(device)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8957],\n",
       "        [-2.5601],\n",
       "        [-3.5439],\n",
       "        [-2.5493],\n",
       "        [-2.6961],\n",
       "        [-3.3406],\n",
       "        [-3.4617],\n",
       "        [-2.5509],\n",
       "        [-2.9211],\n",
       "        [-2.6819],\n",
       "        [-2.5985],\n",
       "        [-2.5631],\n",
       "        [-3.0135],\n",
       "        [-2.8569],\n",
       "        [-2.7235],\n",
       "        [-2.6451],\n",
       "        [-2.8470],\n",
       "        [-3.0090],\n",
       "        [-2.6483],\n",
       "        [-3.4969],\n",
       "        [-2.9705],\n",
       "        [-2.5311],\n",
       "        [-2.5234],\n",
       "        [-2.6296],\n",
       "        [-2.5152],\n",
       "        [-2.6522],\n",
       "        [-2.6092],\n",
       "        [-2.8203],\n",
       "        [-2.8187],\n",
       "        [-2.5085],\n",
       "        [-3.0385],\n",
       "        [-2.5927],\n",
       "        [-2.9402],\n",
       "        [-3.0706],\n",
       "        [-3.5742],\n",
       "        [-2.5162],\n",
       "        [-2.6793],\n",
       "        [-2.4932],\n",
       "        [-2.8577],\n",
       "        [-3.3101],\n",
       "        [-2.7650],\n",
       "        [-3.3834],\n",
       "        [-2.8281],\n",
       "        [-2.8764],\n",
       "        [-2.7050],\n",
       "        [-2.6361],\n",
       "        [-3.3310],\n",
       "        [-2.4996],\n",
       "        [-2.7468],\n",
       "        [-2.5675],\n",
       "        [-2.6221],\n",
       "        [-3.4675],\n",
       "        [-2.9469],\n",
       "        [-3.4238],\n",
       "        [-2.5019],\n",
       "        [-2.5831],\n",
       "        [-2.5516],\n",
       "        [-2.5412],\n",
       "        [-2.5180],\n",
       "        [-2.9162],\n",
       "        [-2.6640],\n",
       "        [-2.6077],\n",
       "        [-2.6157],\n",
       "        [-2.7964],\n",
       "        [-2.9634],\n",
       "        [-3.0056],\n",
       "        [-2.8754],\n",
       "        [-3.8097],\n",
       "        [-3.5613],\n",
       "        [-3.4336],\n",
       "        [-2.9022],\n",
       "        [-3.0611],\n",
       "        [-2.9309],\n",
       "        [-2.5432],\n",
       "        [-3.3782],\n",
       "        [-3.1663],\n",
       "        [-2.7846],\n",
       "        [-2.9559],\n",
       "        [-2.9197],\n",
       "        [-2.8146],\n",
       "        [-2.6065],\n",
       "        [-2.5135],\n",
       "        [-2.8812],\n",
       "        [-3.0396],\n",
       "        [-2.9544],\n",
       "        [-3.8977],\n",
       "        [-2.8480],\n",
       "        [-3.0815],\n",
       "        [-2.8595],\n",
       "        [-2.6589],\n",
       "        [-2.5904],\n",
       "        [-2.5568],\n",
       "        [-2.5159],\n",
       "        [-2.6328],\n",
       "        [-2.5121],\n",
       "        [-3.5241],\n",
       "        [-2.7352],\n",
       "        [-2.5300],\n",
       "        [-2.9971],\n",
       "        [-2.6924],\n",
       "        [-2.5815],\n",
       "        [-3.5182],\n",
       "        [-2.5496],\n",
       "        [-3.1657],\n",
       "        [-2.8345],\n",
       "        [-2.5774],\n",
       "        [-2.9933],\n",
       "        [-2.9388],\n",
       "        [-2.6789],\n",
       "        [-2.6603],\n",
       "        [-2.7023],\n",
       "        [-2.9993],\n",
       "        [-2.5481],\n",
       "        [-2.7131],\n",
       "        [-2.9753],\n",
       "        [-2.9020],\n",
       "        [-2.8460],\n",
       "        [-2.9368],\n",
       "        [-2.5552],\n",
       "        [-3.4356],\n",
       "        [-3.1937],\n",
       "        [-2.5864],\n",
       "        [-2.8640],\n",
       "        [-2.5774],\n",
       "        [-2.8226],\n",
       "        [-3.0806],\n",
       "        [-2.7224],\n",
       "        [-3.3818],\n",
       "        [-2.7250],\n",
       "        [-2.9045],\n",
       "        [-2.8683],\n",
       "        [-3.3735],\n",
       "        [-2.9626],\n",
       "        [-2.9923],\n",
       "        [-2.9418],\n",
       "        [-2.4618],\n",
       "        [-3.0243],\n",
       "        [-2.6501],\n",
       "        [-2.6248],\n",
       "        [-2.6825],\n",
       "        [-2.8313],\n",
       "        [-2.7972],\n",
       "        [-2.9198],\n",
       "        [-2.5712],\n",
       "        [-2.5365],\n",
       "        [-2.6952],\n",
       "        [-2.9710],\n",
       "        [-3.0149],\n",
       "        [-2.5761],\n",
       "        [-2.4379],\n",
       "        [-2.8057],\n",
       "        [-2.5560],\n",
       "        [-2.8442],\n",
       "        [-3.4460],\n",
       "        [-3.0804],\n",
       "        [-2.9207],\n",
       "        [-2.7162],\n",
       "        [-2.5994],\n",
       "        [-3.8494],\n",
       "        [-2.9817],\n",
       "        [-2.6763],\n",
       "        [-3.6010],\n",
       "        [-2.5718],\n",
       "        [-2.5814],\n",
       "        [-2.9084],\n",
       "        [-2.9899],\n",
       "        [-2.8703],\n",
       "        [-3.6404],\n",
       "        [-2.8873],\n",
       "        [-2.5441],\n",
       "        [-2.9588],\n",
       "        [-3.0104],\n",
       "        [-2.5391],\n",
       "        [-3.5636],\n",
       "        [-3.4471],\n",
       "        [-2.5874],\n",
       "        [-2.8339],\n",
       "        [-2.8952],\n",
       "        [-2.9858],\n",
       "        [-2.6265],\n",
       "        [-2.6666],\n",
       "        [-2.7755],\n",
       "        [-2.8585],\n",
       "        [-2.6981],\n",
       "        [-2.8184],\n",
       "        [-3.6769],\n",
       "        [-2.7344],\n",
       "        [-2.6559],\n",
       "        [-2.9410],\n",
       "        [-2.5092],\n",
       "        [-2.5938],\n",
       "        [-3.3078],\n",
       "        [-2.5417],\n",
       "        [-3.4268],\n",
       "        [-3.7787],\n",
       "        [-2.6494],\n",
       "        [-2.6193],\n",
       "        [-3.4729],\n",
       "        [-3.5956]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class LSTMPredictor(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, n_layers=2):\n",
    "#         super(LSTMPredictor, self).__init__()\n",
    "\n",
    "#         self.ltsm = nn.LSTM(\n",
    "#             input_size=input_size,\n",
    "#             hidden_size=hidden_size,\n",
    "#             num_layers=n_layers,\n",
    "#             batch_first=True,\n",
    "#         )\n",
    "#     def forward(self, sequences):\n",
    "#         lstm_out, (hn, cn) = self.ltsm(sequences)\n",
    "#         return lstm_out\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(29, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid(),\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=29, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCEWithLogitsLoss()\n",
      "epoch: 0 loss = 0.27131471037864685, test loss = 6.1112236976623535\n",
      "epoch: 100 loss = 0.29311394691467285, test loss = 0.3599291145801544\n",
      "epoch: 200 loss = 0.28533080220222473, test loss = 0.3751828670501709\n",
      "epoch: 300 loss = 0.3075217604637146, test loss = 0.32357585430145264\n",
      "epoch: 400 loss = 0.2144707888364792, test loss = 0.28057345747947693\n",
      "epoch: 500 loss = 0.2338893711566925, test loss = 0.351945161819458\n",
      "epoch: 600 loss = 0.2870742082595825, test loss = 0.4330994784832001\n",
      "epoch: 700 loss = 0.2800848186016083, test loss = 0.39690959453582764\n",
      "epoch: 800 loss = 0.2982621192932129, test loss = 0.43733519315719604\n",
      "epoch: 900 loss = 0.19521553814411163, test loss = 0.2449607402086258\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "print(loss_fn)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_logits = model(X_train).squeeze()\n",
    "    y_preds = torch.round(torch.sigmoid(y_logits)).float()\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_test_logits = model(X_test).squeeze()\n",
    "        y_test_preds = torch.round(torch.sigmoid(y_test_logits)).float()\n",
    "\n",
    "        # print(y_test_preds.shape)\n",
    "        # print(y_test.shape)\n",
    "        test_loss = loss_fn(y_test_logits, y_test)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch} loss = {loss}, test loss = {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1.], grad_fn=<RoundBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.round(torch.sigmoid(model(X_train).squeeze())).float())\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_forcast_data(stock_name, period=\"5d\", interval=\"1m\"):\n",
    "    recent_data = yf.download(stock_name, period=period, interval=interval)\n",
    "    recent_data = recent_data.drop(columns=[\"Adj Close\", \"Volume\"])\n",
    "\n",
    "    segment = 390 if interval == \"1m\" else 7\n",
    "\n",
    "    for i in range(1, segment):\n",
    "        recent_data[f\"Open t - {i}\"] = recent_data[\"Open\"].shift(i)\n",
    "        recent_data[f\"Close t - {i}\"] = recent_data[\"Close\"].shift(i)\n",
    "        recent_data[f\"High t - {i}\"] = recent_data[\"High\"].shift(i)\n",
    "        recent_data[f\"Low t - {i}\"] = recent_data[\"Low\"].shift(i)\n",
    "\n",
    "    recent_data.dropna(inplace=True)\n",
    "    first_timestamp = recent_data.index[0]\n",
    "\n",
    "    if first_timestamp.time() != pd.Timestamp(\"09:30:00\").time():\n",
    "        index = recent_data.index.get_loc(\n",
    "            recent_data[\n",
    "                recent_data.index.time == pd.Timestamp(\"09:30:00\").time()\n",
    "            ].index[0]\n",
    "        )\n",
    "        recent_data = recent_data.iloc[index:]\n",
    "\n",
    "    # Split data into daily segments\n",
    "    recent_data[\"day_index\"] = recent_data.index.date\n",
    "    recent_data[\"day_index\"], _ = pd.factorize(recent_data[\"day_index\"])\n",
    "    daily_data = [group for _, group in recent_data.groupby(\"day_index\")]\n",
    "\n",
    "    # Add movement column to each daily DataFrame\n",
    "\n",
    "\n",
    "    combined_data = pd.concat(daily_data)\n",
    "\n",
    "    last_hour_data = combined_data.groupby(\"day_index\").apply(lambda x: x.iloc[-1])\n",
    "    last_hour_data.dropna(inplace=True)\n",
    "\n",
    "    return last_hour_data.iloc[-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<RoundBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_data = prepare_forcast_data(stock_name, period=\"1y\", interval=\"1h\")\n",
    "input_tensor = torch.from_numpy(pred_data.values)\n",
    "input_tensor =input_tensor.to(torch.float32)\n",
    "raw_answer = model(input_tensor).squeeze()\n",
    "answer = torch.round(torch.sigmoid(raw_answer)).float()\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_loop_data(stock_name, period=\"5d\", interval=\"1m\",back_time=5, answers =[]):\n",
    "\n",
    "    recent_data = yf.download(stock_name, period=period, interval=interval)\n",
    "\n",
    "    data_200 = yf.download(stock_name, period=period, interval=interval).tail(len(recent_data) + 201)\n",
    "    data_200 = data_200.drop(columns=[\"Adj Close\"])\n",
    "\n",
    "    data_200.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "    #recent_data = data_200.tail(len(recent_data))\n",
    "\n",
    "\n",
    "    recent_data = recent_data.dropna()\n",
    "    for i in range(back_time):\n",
    "        recent_data[f\"Open t - {i+1}\"] = recent_data[\"Open\"].shift((i+1))\n",
    "        recent_data[f\"Close t - {i+1}\"] = recent_data[\"Close\"].shift((i+1))\n",
    "        recent_data[f\"High t - {i+1}\"] = recent_data[\"High\"].shift((i+1))\n",
    "        recent_data[f\"Low t - {i+1}\"] = recent_data[\"Low\"].shift((i+1))\n",
    "    recent_data[\"movement\"] = (recent_data[\"Close\"] > recent_data[\"Open\"]).astype(int)\n",
    "\n",
    "    # recent_data = recent_data.tail(1)\n",
    "    # add_plot = mpf.make_addplot(recent_data[\"200_day\"], color=\"blue\", linestyle=\"--\")\n",
    "\n",
    "    return recent_data\n",
    "\n",
    "#recent_data = prepare_test_loop_data(stock_name,back_time=1,answers=[answer])\n",
    "#recent_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x42 and 29x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m check_y_tensor \u001b[38;5;241m=\u001b[39m check_y_tensor\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# print(check_data_last.to_markdown(), \"\\n\\n\\n\")\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m answer \u001b[38;5;241m=\u001b[39m model(check_X_tensor)\n\u001b[0;32m     35\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(answer, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x42 and 29x128)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "answers = []\n",
    "forcast = 10\n",
    "check_data = prepare_test_loop_data(\n",
    "    interval=\"1m\", back_time=10, period=\"1d\", stock_name=stock_name\n",
    ")\n",
    "date_range = pd.date_range(\n",
    "    start=check_data.index[-1], periods=forcast, freq=\"1T\"\n",
    ")  # Generate a date range\n",
    "\n",
    "\n",
    "\n",
    "for i in range(forcast):\n",
    "    # for i in answers:\n",
    "\n",
    "    check_data_last = check_data.tail(1)\n",
    "    check_X = check_data_last.drop([\"Close\", \"Volume\", \"High\", \"Low\",\"movement\"], axis=1)\n",
    "    check_y = check_data_last[[\"movement\"]]\n",
    "\n",
    "    # print(check_data.tail(6).to_markdown())\n",
    "    # print(X.shape)\n",
    "\n",
    "    check_X_tensor = torch.from_numpy(check_X.values)\n",
    "    check_y_tensor = torch.from_numpy(check_y.values)\n",
    "\n",
    "    check_X_tensor = check_X_tensor.to(torch.float32).to(device)\n",
    "    check_y_tensor = check_y_tensor.to(torch.float32).to(device)\n",
    "\n",
    "    # print(check_data_last.to_markdown(), \"\\n\\n\\n\")\n",
    "\n",
    "    answer = model(check_X_tensor)\n",
    "    a = torch.softmax(answer, dim=1).argmax(dim=1)\n",
    "    print(a)\n",
    "\n",
    "    answer = answer.detach().cpu().numpy()\n",
    "\n",
    "    answer = np.append(answer[0],check_X[\"Close t - 1\"])\n",
    "    answers.append(answer)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Close\": [answers[-1][0]],\n",
    "            \"High\": [answers[-1][1]],\n",
    "            \"Low\": [answers[-1][2]],\n",
    "            \"Open\": [answers[-1][3]],\n",
    "            \"Adj Close\": [0],\n",
    "            \"Volume\": [0],\n",
    "        },\n",
    "        index=[date_range[i]],\n",
    "    )\n",
    "\n",
    "    check_data = check_data._append(df)\n",
    "    for i in range(10):\n",
    "        check_data[f\"Open t - {i+1}\"] = check_data[\"Open\"].shift((i + 1))\n",
    "        check_data[f\"Close t - {i+1}\"] = check_data[\"Close\"].shift((i + 1))\n",
    "        check_data[f\"High t - {i+1}\"] = check_data[\"High\"].shift((i + 1))\n",
    "        check_data[f\"Low t - {i+1}\"] = check_data[\"Low\"].shift((i + 1))\n",
    "    recent_data[\"movement\"] = (recent_data[\"Close\"] > recent_data[\"Open\"]).astype(int)\n",
    "\n",
    "    # check_data.dropna(inplace=True)\n",
    "# print(check_data.to_markdown())\n",
    "\n",
    "# print(check_data)\n",
    "# print(answers)\n",
    "\n",
    "# sns.catplot(answer[0][:],label=\"Predicted\")\n",
    "last_elements = [arr[0] for arr in answers]\n",
    "\n",
    "recent_data = prepare_data(stock_name, period=\"1d\", interval=\"1m\")\n",
    "# print(\"Converted index to datetime\")\n",
    "\n",
    "answers_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            recent_data,\n",
    "            columns=[\"Close\", \"High\", \"Low\", \"Open\",\"movement\"],\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            answers, columns=[\"movement\"], index=date_range\n",
    "        ),\n",
    "    ]\n",
    ").iloc[200:]\n",
    "\n",
    "# print(answers_df.tail(100))\n",
    "\n",
    "mpf.plot(\n",
    "    answers_df,\n",
    "    type=\"candle\",\n",
    "    style=\"charles\",\n",
    "    title=f\"{stock_name} Candlestick Chart\",\n",
    "    ylabel=\"Price\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 64\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 24\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Build model\n",
    "class stonks(nn.Module):\n",
    "    def __init__(self, input_features, output_features, hidden_units=8):\n",
    "\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "             nn.ReLU(), \n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features), \n",
    "            nn.Sigmoid(),\n",
    "     \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "# Create an instance of BlobModel and send it to the target device\n",
    "model = stonks(input_features=X_train.size()[1], \n",
    "                    output_features=1, \n",
    "                    hidden_units=8).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss and optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=0.1) # exercise: try changing the learning rate here and seeing what happens to the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1976e-05],\n",
      "        [6.7180e-05],\n",
      "        [2.2683e-05],\n",
      "        [2.2327e-05]], grad_fn=<SliceBackward0>)\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Make prediction logits with model\n",
    "y_logits = model(X_test.to(device))\n",
    "\n",
    "# Perform softmax calculation on logits across dimension 1 to get prediction probabilities\n",
    "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "print(y_logits[:5])\n",
    "print(y_pred_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 100 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 200 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 300 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 400 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 500 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 600 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 700 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 800 | Loss: 75.00000,| Test Loss: 2.40205\n",
      "Epoch: 900 | Loss: 75.00000,| Test Loss: 2.40205\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "#torch.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 1000\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = model(X_train) # model outputs raw logits \n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
    "    # print(y_logits)\n",
    "    # 2. Calculate loss and accuracy\n",
    "  \n",
    "    loss = loss_fn(y_pred.to(torch.float32), y_train.squeeze()) \n",
    "  \n",
    "\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.requires_grad = True\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass\n",
    "      test_logits = model(X_test)\n",
    "      test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "      # 2. Calculate test loss and accuracy\n",
    "      test_loss = loss_fn(test_logits, y_test)\n",
    "\n",
    "\n",
    "    # Print out what's happening\n",
    "      if epoch % 100 == 0:\n",
    "          print(f\"Epoch: {epoch} | Loss: {loss:.5f},| Test Loss: {test_loss:.5f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
